# Deep Learning for Computer Vision: CNN, Faster R-CNN, and ViT on MNIST

Explore deep learning techniques including **CNN**, **Faster R-CNN**, and **Vision Transformer (ViT)** for image classification using the **MNIST** dataset. This lab includes model comparisons, fine-tuning with pretrained models, and performance evaluation.

---

## **Objective**

The main goal of this lab is to explore and implement different deep learning architectures for **computer vision tasks**, particularly focused on classifying the MNIST dataset. This lab covers the following models and techniques:

- **Convolutional Neural Networks (CNN)**
- **Faster R-CNN**
- **Vision Transformer (ViT)**

---

## **Tasks**

### **Part 1: CNN Classifier**
1. **CNN Model**  
   Build a CNN model using **PyTorch** to classify the MNIST dataset. The model includes layers like Convolution, Pooling, and Fully Connected layers. Hyperparameters like kernels, padding, stride, and optimizers are defined.
   
2. **Faster R-CNN Model**  
   Implement a **Faster R-CNN** model for MNIST classification.

3. **Comparison**  
   Compare the performance of both CNN and Faster R-CNN models using various metrics:
   - Accuracy
   - F1 Score
   - Loss
   - Training Time

4. **Fine-Tuning with Pretrained Models**  
   Fine-tune pretrained models like **VGG16** and **AlexNet** on the MNIST dataset and compare the results to CNN and Faster R-CNN models.

---

### **Part 2: Vision Transformer (ViT)**
1. **ViT Model**  
   Implement a **Vision Transformer (ViT)** model for MNIST image classification from scratch, based on an online tutorial.

2. **Comparison**  
   Analyze and compare the results of the ViT model with CNN and Faster R-CNN from Part 1.

---

## **Tools Used**

- **PyTorch**: Framework for building and training deep learning models.
- **Google Colab / Kaggle**: Platforms for running experiments and code.
- **GitHub**: For version control and project sharing.

---

## **Results**

- **CNN & Faster R-CNN Performance**: Evaluated using accuracy, F1 score, and training time.
- **ViT Performance**: Compared with CNN and Faster R-CNN to analyze the effectiveness of transformer-based models in computer vision.

---

## **Conclusion**

This lab demonstrates how different deep learning models (**CNN**, **Faster R-CNN**, and **Vision Transformer**) can be applied to image classification tasks. The comparisons help evaluate which model performs best for the MNIST dataset.

---

## **Getting Started**

To run the code, follow these steps:

### **Prerequisites**
- Python 3.x
- PyTorch
- Kaggle environment (for running the notebooks)

### **Installation**
1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/repository-name.git
